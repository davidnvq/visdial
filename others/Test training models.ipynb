{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOME_PATH /home/quanguet\n",
      "DATA_PATH /home/quanguet/datasets/visdial\n",
      "HOME_PATH /home/quanguet\n",
      "DATA_PATH /home/quanguet/datasets/visdial\n",
      "HOME_PATH /home/quanguet\n",
      "DATA_PATH /home/quanguet/datasets/visdial\n",
      "HOME_PATH /home/quanguet\n",
      "DATA_PATH /home/quanguet/datasets/visdial\n",
      "HOME_PATH /home/quanguet\n",
      "DATA_PATH /home/quanguet/datasets/visdial\n",
      "HOME_PATH /home/quanguet\n",
      "DATA_PATH /home/quanguet/datasets/visdial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 2500/45238 [00:00<00:03, 12343.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val2018] Tokenizing questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45238/45238 [00:03<00:00, 13272.73it/s]\n",
      "  4%|▍         | 1318/34822 [00:00<00:02, 13172.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val2018] Tokenizing answers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34822/34822 [00:02<00:00, 13271.46it/s]\n",
      "100%|██████████| 2064/2064 [00:00<00:00, 10977.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val2018] Tokenizing captions...\n",
      "img_ids         torch.Size([2])\n",
      "num_rounds      torch.Size([2])\n",
      "opts            torch.Size([2, 10, 100, 25])\n",
      "opts_in         torch.Size([2, 10, 100, 25])\n",
      "opts_out        torch.Size([2, 10, 100, 25])\n",
      "opts_len        torch.Size([2, 10, 100])\n",
      "opts_in_len     torch.Size([2, 10, 100])\n",
      "opts_out_len    torch.Size([2, 10, 100])\n",
      "ans             torch.Size([2, 10, 25])\n",
      "ans_in          torch.Size([2, 10, 25])\n",
      "ans_out         torch.Size([2, 10, 25])\n",
      "ans_len         torch.Size([2, 10])\n",
      "ans_in_len      torch.Size([2, 10])\n",
      "ans_out_len     torch.Size([2, 10])\n",
      "ans_ind         torch.Size([2, 10])\n",
      "gt_relevance    torch.Size([2, 100])\n",
      "round_id        torch.Size([2])\n",
      "img_feat        torch.Size([2, 36, 2048])\n",
      "ques_tokens     torch.Size([2, 10, 25])\n",
      "hist_tokens     torch.Size([2, 10, 50])\n",
      "ques_len        torch.Size([2, 10])\n",
      "hist_len        torch.Size([2, 10])\n",
      "concat_hist_tokens torch.Size([2, 10, 500])\n",
      "concat_hist_len torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "run debug.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def untokenize(ids):\n",
    "    \"ids: numpy array\"\n",
    "    tokens = \" \".join(dataset.tokenizer.convert_ids_to_tokens(ids))\n",
    "    tokens = tokens.replace('<PAD>', ' ')\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 14,  22,  30,  37,  47,  57,  64,  78,  86,  99],\n",
       "        [ 13,  26,  37,  46,  56,  72,  83,  92, 100, 111]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['concat_hist_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a bedroom is filled with lots of posters and a busy computer desk </S>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      "\n",
      "a bedroom is filled with lots of posters and a busy computer desk </S> is the photo in color ? yes </S>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      "\n",
      "a bedroom is filled with lots of posters and a busy computer desk </S> is the photo in color ? yes </S> is it a professional photo ? no </S>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(untokenize(batch['concat_hist_tokens'][0][i].numpy()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs import get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "run visdial/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'lf_gen_lstm'\n",
    "\n",
    "def test_model(name):\n",
    "    print(name)\n",
    "    \n",
    "    config = get_config(name)\n",
    "\n",
    "    model = get_model(config, name)\n",
    "    print(\"\\ntraining\")\n",
    "    out = model(batch)\n",
    "\n",
    "    for key in out:\n",
    "        if out[key] is not None:\n",
    "            print(key, out[key].shape)\n",
    "\n",
    "    print(\"\\nvalidation\")\n",
    "    model = model.eval()\n",
    "    out = model(batch)\n",
    "    for key in out:\n",
    "        if out[key] is not None:\n",
    "            print(key, out[key].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LateFusion Generative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LateFusion Generative\n",
    "# test_model('lf_gen_lstm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LateFusion Discriminative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_model('lf_disc_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_model('lf_misc_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_gen_lstm\n",
      "\n",
      "training\n",
      "hist torch.Size([20, 1024])\n",
      "ans_out_scores torch.Size([2, 10, 25, 11322])\n",
      "\n",
      "validation\n",
      "hist torch.Size([20, 1024])\n",
      "opts_out_scores torch.Size([2, 10, 100])\n"
     ]
    }
   ],
   "source": [
    "test_model('attn_gen_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20480 / 2 / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_disc_lstm\n",
      "\n",
      "training\n",
      "hist torch.Size([20, 1024])\n",
      "opt_scores torch.Size([2, 10, 100])\n",
      "\n",
      "validation\n",
      "hist torch.Size([20, 1024])\n",
      "opt_scores torch.Size([2, 10, 100])\n"
     ]
    }
   ],
   "source": [
    "test_model('attn_disc_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(3.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HI\n"
     ]
    }
   ],
   "source": [
    "y = {}\n",
    "if y.get('hi') is None:\n",
    "    print(\"HI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_misc_lstm\n",
      "\n",
      "training\n",
      "hist torch.Size([20, 1024])\n",
      "scores torch.Size([2, 10, 100])\n",
      "ans_out_scores torch.Size([2, 10, 25, 11322])\n",
      "\n",
      "validation\n",
      "hist torch.Size([20, 1024])\n",
      "scores torch.Size([2, 10, 100])\n",
      "opts_out_scores torch.Size([2, 10, 100])\n"
     ]
    }
   ],
   "source": [
    "test_model('attn_misc_lstm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
