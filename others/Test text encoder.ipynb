{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "run visdial/encoders/text_encoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HistEncoder(\n",
       "  (encoder): DynamicRNN(\n",
       "    (rnn_module): LSTM(300, 512, num_layers=2)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_encoder = HistEncoder(DynamicRNN(torch.nn.LSTM(300, 512, num_layers=2)), hidden_size=512)\n",
    "hist_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = torch.randn(16, 10, 10, 20, 300)\n",
    "hist_len = torch.randint(1, 20, size=(16, 10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = hist_encoder(hist, hist_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([160, 10, 512])\n",
      "torch.Size([160, 10])\n"
     ]
    }
   ],
   "source": [
    "for o in out: \n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuesEncoder(\n",
       "  (encoder): DynamicRNN(\n",
       "    (rnn_module): LSTM(300, 512, num_layers=2)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ques_encoder = QuesEncoder(DynamicRNN(torch.nn.LSTM(300, 512, num_layers=2)), hidden_size=512)\n",
    "ques_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques = torch.randn(16, 10, 20, 300)\n",
    "ques_len = torch.randint(1, 20, size=(16, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques_out = ques_encoder(ques, ques_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([160, 20, 512])\n",
      "torch.Size([160, 20])\n"
     ]
    }
   ],
   "source": [
    "for q in ques_out:\n",
    "    print(q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embed = TextEmbeddings(vocab_size=11322, embedding_size=300, hidden_size=512, has_position=True, has_hidden_layer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = torch.randint(0, 11322, size=(16, 10, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 10, 25, 300])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embed(tokens).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = {\n",
    "    'ques_tokens' : torch.randint(0, 11322, size=(16, 10, 25)),\n",
    "    'ques_len' : torch.randint(1, 25, size=(16, 10)),\n",
    "    'hist_tokens' : torch.randint(0, 11322, size=(16, 10, 10, 25)),\n",
    "    'hist_len' : torch.randint(1, 25, size=(16, 10, 10)), \n",
    "    'img_feat' : torch.randn(16, 36, 2048)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoder = TextEncoder(text_embed, hist_encoder, ques_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextEncoder(\n",
       "  (text_embeddings): TextEmbeddings(\n",
       "    (tok_embedding): Embedding(11322, 300, padding_idx=0)\n",
       "    (pos_embedding): PositionalEmbedding()\n",
       "  )\n",
       "  (hist_encoder): HistEncoder(\n",
       "    (encoder): DynamicRNN(\n",
       "      (rnn_module): LSTM(300, 512, num_layers=2)\n",
       "    )\n",
       "  )\n",
       "  (ques_encoder): QuesEncoder(\n",
       "    (encoder): DynamicRNN(\n",
       "      (rnn_module): LSTM(300, 512, num_layers=2)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = text_encoder(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([160, 10, 512])\n",
      "torch.Size([160, 25, 512])\n",
      "torch.Size([160, 10])\n",
      "torch.Size([160, 25])\n"
     ]
    }
   ],
   "source": [
    "for o in out:\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "run visdial/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOME_PATH /home/quanguet\n",
      "DATA_PATH /home/quanguet/datasets/visdial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/quanguet/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "  2%|▏         | 1072/45238 [00:00<00:04, 10713.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val2018] Tokenizing questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45238/45238 [00:03<00:00, 12647.35it/s]\n",
      "  4%|▍         | 1310/34822 [00:00<00:02, 13098.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val2018] Tokenizing answers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34822/34822 [00:02<00:00, 13413.98it/s]\n",
      "100%|██████████| 2064/2064 [00:00<00:00, 10963.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val2018] Tokenizing captions...\n",
      "img_ids         torch.Size([2])\n",
      "num_rounds      torch.Size([2])\n",
      "opts            torch.Size([2, 10, 100, 25])\n",
      "opts_in         torch.Size([2, 10, 100, 25])\n",
      "opts_out        torch.Size([2, 10, 100, 25])\n",
      "opts_len        torch.Size([2, 10, 100])\n",
      "opts_in_len     torch.Size([2, 10, 100])\n",
      "opts_out_len    torch.Size([2, 10, 100])\n",
      "ans             torch.Size([2, 10, 25])\n",
      "ans_in          torch.Size([2, 10, 25])\n",
      "ans_out         torch.Size([2, 10, 25])\n",
      "ans_len         torch.Size([2, 10])\n",
      "ans_in_len      torch.Size([2, 10])\n",
      "ans_out_len     torch.Size([2, 10])\n",
      "ans_ind         torch.Size([2, 10])\n",
      "gt_relevance    torch.Size([2, 100])\n",
      "round_id        torch.Size([2])\n",
      "img_feat        torch.Size([2, 36, 2048])\n",
      "ques_tokens     torch.Size([2, 10, 25])\n",
      "hist_tokens     torch.Size([2, 10, 10, 50])\n",
      "ques_len        torch.Size([2, 10])\n",
      "hist_len        torch.Size([2, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "run debug.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOME_PATH /home/quanguet\n",
      "DATA_PATH /home/quanguet/datasets/visdial\n"
     ]
    }
   ],
   "source": [
    "run configs/lstm_config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings = TextEmbeddings(**config['model']['text_embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_lstm_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisdialModel(\n",
       "  (encoder): Encoder(\n",
       "    (text_encoder): TextEncoder(\n",
       "      (text_embeddings): TextEmbeddings(\n",
       "        (tok_embedding): Embedding(11322, 300, padding_idx=0)\n",
       "        (pos_embedding): PositionalEmbedding()\n",
       "      )\n",
       "      (hist_encoder): HistEncoder(\n",
       "        (encoder): DynamicRNN(\n",
       "          (rnn_module): LSTM(300, 512, num_layers=2)\n",
       "        )\n",
       "      )\n",
       "      (ques_encoder): QuesEncoder(\n",
       "        (encoder): DynamicRNN(\n",
       "          (rnn_module): LSTM(300, 512, num_layers=2)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (img_encoder): ImageEncoder(\n",
       "      (img_linear): Sequential(\n",
       "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (1): Dropout(p=0.2)\n",
       "      )\n",
       "    )\n",
       "    (attn_encoder): CrossAttentionEncoder(\n",
       "      (cross_attn_encoder): Sequential(\n",
       "        (0): CrossAttentionLayer(\n",
       "          (attns): ModuleList(\n",
       "            (0): MultiHeadAttention(\n",
       "              (dropout): Dropout(p=0.2)\n",
       "              (x_proj_linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (y_proj_linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (1): MultiHeadAttention(\n",
       "              (dropout): Dropout(p=0.2)\n",
       "              (x_proj_linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (y_proj_linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (2): MultiHeadAttention(\n",
       "              (dropout): Dropout(p=0.2)\n",
       "              (x_proj_linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (y_proj_linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (norms): ModuleList(\n",
       "            (0): NormalSubLayer(\n",
       "              (linear): Sequential(\n",
       "                (0): Linear(in_features=1536, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace)\n",
       "                (2): Dropout(p=0.2)\n",
       "              )\n",
       "            )\n",
       "            (1): NormalSubLayer(\n",
       "              (linear): Sequential(\n",
       "                (0): Linear(in_features=1536, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace)\n",
       "                (2): Dropout(p=0.2)\n",
       "              )\n",
       "            )\n",
       "            (2): NormalSubLayer(\n",
       "              (linear): Sequential(\n",
       "                (0): Linear(in_features=1536, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace)\n",
       "                (2): Dropout(p=0.2)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): CrossAttentionLayer(\n",
       "          (attns): ModuleList(\n",
       "            (0): MultiHeadAttention(\n",
       "              (dropout): Dropout(p=0.2)\n",
       "              (x_proj_linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (y_proj_linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (1): MultiHeadAttention(\n",
       "              (dropout): Dropout(p=0.2)\n",
       "              (x_proj_linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (y_proj_linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (2): MultiHeadAttention(\n",
       "              (dropout): Dropout(p=0.2)\n",
       "              (x_proj_linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (y_proj_linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (norms): ModuleList(\n",
       "            (0): NormalSubLayer(\n",
       "              (linear): Sequential(\n",
       "                (0): Linear(in_features=1536, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace)\n",
       "                (2): Dropout(p=0.2)\n",
       "              )\n",
       "            )\n",
       "            (1): NormalSubLayer(\n",
       "              (linear): Sequential(\n",
       "                (0): Linear(in_features=1536, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace)\n",
       "                (2): Dropout(p=0.2)\n",
       "              )\n",
       "            )\n",
       "            (2): NormalSubLayer(\n",
       "              (linear): Sequential(\n",
       "                (0): Linear(in_features=1536, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace)\n",
       "                (2): Dropout(p=0.2)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (summaries): ModuleList(\n",
       "      (0): SummaryAttention(\n",
       "        (attn_linear): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): ReLU(inplace)\n",
       "          (2): Linear(in_features=512, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SummaryAttention(\n",
       "        (attn_linear): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): ReLU(inplace)\n",
       "          (2): Linear(in_features=512, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): SummaryAttention(\n",
       "        (attn_linear): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): ReLU(inplace)\n",
       "          (2): Linear(in_features=512, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (encoder_linear): Sequential(\n",
       "      (0): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (1): ReLU(inplace)\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (text_embeddings): TextEmbeddings(\n",
       "      (tok_embedding): Embedding(11322, 300, padding_idx=0)\n",
       "      (pos_embedding): PositionalEmbedding()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 10, 50])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['hist_tokens'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Length of all samples has to be greater than 0, but found an element in 'lengths' that is <= 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-b07a0d9052c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/Repos/visdial/visdial/encoders/encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mques_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mbatch_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mques_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/Repos/visdial/visdial/encoders/text_encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# hist_mask: shape [bs * num_hist, num_rounds]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mques_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mques_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ques_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hist_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mques_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/Repos/visdial/visdial/encoders/text_encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hist, hist_len)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0;31m# shape: [num_layers, BS, HS] if Not bidirectional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0;31m# shape: hn = [num_layers, bs * num_hist * num_rounds, hidden_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                 \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0;31m# shape: [bs * num_hist * num_rounds, hidden_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/Repos/visdial/visdial/common/dynamic_rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, len_x, initial_state)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;31m# Convert to packed sequence batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0mpacked_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msorted_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0;31m# Check init_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Length of all samples has to be greater than 0, but found an element in 'lengths' that is <= 0"
     ]
    }
   ],
   "source": [
    "model.encoder(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([160, 512])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0466,  0.0301, -0.0358,  ...,  0.0406, -0.0049,  0.0362],\n",
       "        [ 0.0468,  0.0303, -0.0372,  ...,  0.0392, -0.0043,  0.0379],\n",
       "        [ 0.0456,  0.0303, -0.0382,  ...,  0.0417, -0.0047,  0.0363],\n",
       "        ...,\n",
       "        [ 0.0406,  0.0287, -0.0372,  ...,  0.0387, -0.0041,  0.0340],\n",
       "        [ 0.0394,  0.0309, -0.0355,  ...,  0.0385, -0.0015,  0.0363],\n",
       "        [ 0.0414,  0.0316, -0.0344,  ...,  0.0399, -0.0042,  0.0372]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[3, 7, 6]],\n",
      "\n",
      "         [[1, 8, 8]],\n",
      "\n",
      "         [[3, 6, 7]],\n",
      "\n",
      "         [[3, 2, 1]]]])\n"
     ]
    }
   ],
   "source": [
    "hist = torch.randint(1, 10, size=(1, 4, 1, 3))\n",
    "print(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 4, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "out = hist.unsqueeze(1).repeat(1, 4, 1, 1, 1)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.tensor([\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
    "    [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
    "    [1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "], device=out.device)\n",
    "mask = mask[None, :, :, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 10, 1, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[1]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]]],\n",
       "\n",
       "\n",
       "         [[[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]]],\n",
       "\n",
       "\n",
       "         [[[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]]],\n",
       "\n",
       "\n",
       "         [[[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]]],\n",
       "\n",
       "\n",
       "         [[[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]]],\n",
       "\n",
       "\n",
       "         [[[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]]],\n",
       "\n",
       "\n",
       "         [[[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]]],\n",
       "\n",
       "\n",
       "         [[[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[0]],\n",
       "\n",
       "          [[0]]],\n",
       "\n",
       "\n",
       "         [[[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[0]]],\n",
       "\n",
       "\n",
       "         [[[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]],\n",
       "\n",
       "          [[1]]]]], device='cuda:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[3, 7, 6]],\n",
       "\n",
       "          [[0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0]]],\n",
       "\n",
       "\n",
       "         [[[3, 7, 6]],\n",
       "\n",
       "          [[1, 8, 8]],\n",
       "\n",
       "          [[0, 0, 0]],\n",
       "\n",
       "          [[0, 0, 0]]],\n",
       "\n",
       "\n",
       "         [[[3, 7, 6]],\n",
       "\n",
       "          [[1, 8, 8]],\n",
       "\n",
       "          [[3, 6, 7]],\n",
       "\n",
       "          [[0, 0, 0]]],\n",
       "\n",
       "\n",
       "         [[[3, 7, 6]],\n",
       "\n",
       "          [[1, 8, 8]],\n",
       "\n",
       "          [[3, 6, 7]],\n",
       "\n",
       "          [[3, 2, 1]]]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.masked_fill(mask == 0, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
