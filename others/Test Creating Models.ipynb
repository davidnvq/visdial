{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "run visdial/encoders/attn_encoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CrossAttentionEncoder(hidden_size=512, num_heads=4, memory_size=1, dropout=0.0, num_cross_attns=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140545574913304"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(net.cross_attn_encoder[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(net.cross_attn_encoder[1]) == id(net.cross_attn_encoder[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7873536)\n"
     ]
    }
   ],
   "source": [
    "total_params = 0\n",
    "for p in net.parameters():\n",
    "    total_params += torch.prod(torch.tensor(p.shape))\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3936768)\n"
     ]
    }
   ],
   "source": [
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs import get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_config = get_config('attn_gen_lstm')\n",
    "ad_config = get_config('attn_disc_lstm')\n",
    "am_config = get_config('attn_misc_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed\n",
      "config_name\n",
      "comet_project\n"
     ]
    }
   ],
   "source": [
    "for key in ag_config:\n",
    "    if not isinstance(ag_config[key], dict):\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "run visdial/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_model = get_model(ag_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.text_encoder.text_embeddings.tok_embedding.weight torch.Size([11322, 300])\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.weight_ih_l0 torch.Size([2048, 300])\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.weight_hh_l0 torch.Size([2048, 512])\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.bias_ih_l0 torch.Size([2048])\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.bias_hh_l0 torch.Size([2048])\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.weight_ih_l0_reverse torch.Size([2048, 300])\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.weight_hh_l0_reverse torch.Size([2048, 512])\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.bias_ih_l0_reverse torch.Size([2048])\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.bias_hh_l0_reverse torch.Size([2048])\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.weight_ih_l1 torch.Size([2048, 1024])\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.weight_hh_l1 torch.Size([2048, 512])\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.bias_ih_l1 torch.Size([2048])\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.bias_hh_l1 torch.Size([2048])\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.weight_ih_l1_reverse torch.Size([2048, 1024])\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.weight_hh_l1_reverse torch.Size([2048, 512])\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.bias_ih_l1_reverse torch.Size([2048])\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.bias_hh_l1_reverse torch.Size([2048])\n",
      "encoder.text_encoder.hist_encoder.hist_linear.weight torch.Size([512, 1024])\n",
      "encoder.text_encoder.hist_encoder.hist_linear.bias torch.Size([512])\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.weight_ih_l0 torch.Size([2048, 300])\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.weight_hh_l0 torch.Size([2048, 512])\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.bias_ih_l0 torch.Size([2048])\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.bias_hh_l0 torch.Size([2048])\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.weight_ih_l0_reverse torch.Size([2048, 300])\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.weight_hh_l0_reverse torch.Size([2048, 512])\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.bias_ih_l0_reverse torch.Size([2048])\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.bias_hh_l0_reverse torch.Size([2048])\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.weight_ih_l1 torch.Size([2048, 1024])\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.weight_hh_l1 torch.Size([2048, 512])\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.bias_ih_l1 torch.Size([2048])\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.bias_hh_l1 torch.Size([2048])\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.weight_ih_l1_reverse torch.Size([2048, 1024])\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.weight_hh_l1_reverse torch.Size([2048, 512])\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.bias_ih_l1_reverse torch.Size([2048])\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.bias_hh_l1_reverse torch.Size([2048])\n",
      "encoder.text_encoder.ques_encoder.ques_linear.weight torch.Size([512, 1024])\n",
      "encoder.text_encoder.ques_encoder.ques_linear.bias torch.Size([512])\n",
      "encoder.img_encoder.img_linear.0.weight torch.Size([512, 2048])\n",
      "encoder.img_encoder.img_linear.0.bias torch.Size([512])\n",
      "encoder.attn_encoder.cross_attn_encoder.0.attns.0.x_memory torch.Size([2, 512])\n",
      "encoder.attn_encoder.cross_attn_encoder.0.attns.0.y_memory torch.Size([2, 512])\n",
      "encoder.attn_encoder.cross_attn_encoder.0.attns.0.x_proj_linear.weight torch.Size([512, 512])\n",
      "encoder.attn_encoder.cross_attn_encoder.0.attns.0.y_proj_linear.weight torch.Size([512, 512])\n",
      "encoder.attn_encoder.cross_attn_encoder.0.attns.1.x_memory torch.Size([2, 512])\n",
      "encoder.attn_encoder.cross_attn_encoder.0.attns.1.y_memory torch.Size([2, 512])\n",
      "encoder.attn_encoder.cross_attn_encoder.0.attns.1.x_proj_linear.weight torch.Size([512, 512])\n",
      "encoder.attn_encoder.cross_attn_encoder.0.attns.1.y_proj_linear.weight torch.Size([512, 512])\n",
      "encoder.attn_encoder.cross_attn_encoder.0.attns.2.x_memory torch.Size([2, 512])\n",
      "encoder.attn_encoder.cross_attn_encoder.0.attns.2.y_memory torch.Size([2, 512])\n",
      "encoder.attn_encoder.cross_attn_encoder.0.attns.2.x_proj_linear.weight torch.Size([512, 512])\n",
      "encoder.attn_encoder.cross_attn_encoder.0.attns.2.y_proj_linear.weight torch.Size([512, 512])\n",
      "encoder.attn_encoder.cross_attn_encoder.0.norms.0.linear.0.weight torch.Size([512, 1536])\n",
      "encoder.attn_encoder.cross_attn_encoder.0.norms.0.linear.0.bias torch.Size([512])\n",
      "encoder.attn_encoder.cross_attn_encoder.0.norms.1.linear.0.weight torch.Size([512, 1536])\n",
      "encoder.attn_encoder.cross_attn_encoder.0.norms.1.linear.0.bias torch.Size([512])\n",
      "encoder.attn_encoder.cross_attn_encoder.0.norms.2.linear.0.weight torch.Size([512, 1536])\n",
      "encoder.attn_encoder.cross_attn_encoder.0.norms.2.linear.0.bias torch.Size([512])\n",
      "encoder.attn_encoder.cross_attn_encoder.1.attns.0.x_memory torch.Size([2, 512])\n",
      "encoder.attn_encoder.cross_attn_encoder.1.attns.0.y_memory torch.Size([2, 512])\n",
      "encoder.attn_encoder.cross_attn_encoder.1.attns.0.x_proj_linear.weight torch.Size([512, 512])\n",
      "encoder.attn_encoder.cross_attn_encoder.1.attns.0.y_proj_linear.weight torch.Size([512, 512])\n",
      "encoder.attn_encoder.cross_attn_encoder.1.attns.1.x_memory torch.Size([2, 512])\n",
      "encoder.attn_encoder.cross_attn_encoder.1.attns.1.y_memory torch.Size([2, 512])\n",
      "encoder.attn_encoder.cross_attn_encoder.1.attns.1.x_proj_linear.weight torch.Size([512, 512])\n",
      "encoder.attn_encoder.cross_attn_encoder.1.attns.1.y_proj_linear.weight torch.Size([512, 512])\n",
      "encoder.attn_encoder.cross_attn_encoder.1.attns.2.x_memory torch.Size([2, 512])\n",
      "encoder.attn_encoder.cross_attn_encoder.1.attns.2.y_memory torch.Size([2, 512])\n",
      "encoder.attn_encoder.cross_attn_encoder.1.attns.2.x_proj_linear.weight torch.Size([512, 512])\n",
      "encoder.attn_encoder.cross_attn_encoder.1.attns.2.y_proj_linear.weight torch.Size([512, 512])\n",
      "encoder.attn_encoder.cross_attn_encoder.1.norms.0.linear.0.weight torch.Size([512, 1536])\n",
      "encoder.attn_encoder.cross_attn_encoder.1.norms.0.linear.0.bias torch.Size([512])\n",
      "encoder.attn_encoder.cross_attn_encoder.1.norms.1.linear.0.weight torch.Size([512, 1536])\n",
      "encoder.attn_encoder.cross_attn_encoder.1.norms.1.linear.0.bias torch.Size([512])\n",
      "encoder.attn_encoder.cross_attn_encoder.1.norms.2.linear.0.weight torch.Size([512, 1536])\n",
      "encoder.attn_encoder.cross_attn_encoder.1.norms.2.linear.0.bias torch.Size([512])\n",
      "encoder.summaries.0.attn_linear.0.weight torch.Size([512, 512])\n",
      "encoder.summaries.0.attn_linear.0.bias torch.Size([512])\n",
      "encoder.summaries.0.attn_linear.2.weight torch.Size([1, 512])\n",
      "encoder.summaries.0.attn_linear.2.bias torch.Size([1])\n",
      "encoder.summaries.1.attn_linear.0.weight torch.Size([512, 512])\n",
      "encoder.summaries.1.attn_linear.0.bias torch.Size([512])\n",
      "encoder.summaries.1.attn_linear.2.weight torch.Size([1, 512])\n",
      "encoder.summaries.1.attn_linear.2.bias torch.Size([1])\n",
      "encoder.summaries.2.attn_linear.0.weight torch.Size([512, 512])\n",
      "encoder.summaries.2.attn_linear.0.bias torch.Size([512])\n",
      "encoder.summaries.2.attn_linear.2.weight torch.Size([1, 512])\n",
      "encoder.summaries.2.attn_linear.2.bias torch.Size([1])\n",
      "encoder.encoder_linear.0.weight torch.Size([512, 1536])\n",
      "encoder.encoder_linear.0.bias torch.Size([512])\n",
      "encoder.encoder_linear.2.weight torch.Size([512, 512])\n",
      "encoder.encoder_linear.2.bias torch.Size([512])\n",
      "decoder.gen_decoder.answer_rnn.weight_ih_l0 torch.Size([2048, 300])\n",
      "decoder.gen_decoder.answer_rnn.weight_hh_l0 torch.Size([2048, 512])\n",
      "decoder.gen_decoder.answer_rnn.bias_ih_l0 torch.Size([2048])\n",
      "decoder.gen_decoder.answer_rnn.bias_hh_l0 torch.Size([2048])\n",
      "decoder.gen_decoder.answer_rnn.weight_ih_l1 torch.Size([2048, 512])\n",
      "decoder.gen_decoder.answer_rnn.weight_hh_l1 torch.Size([2048, 512])\n",
      "decoder.gen_decoder.answer_rnn.bias_ih_l1 torch.Size([2048])\n",
      "decoder.gen_decoder.answer_rnn.bias_hh_l1 torch.Size([2048])\n",
      "decoder.gen_decoder.lstm_to_words.weight torch.Size([11322, 512])\n",
      "decoder.gen_decoder.lstm_to_words.bias torch.Size([11322])\n"
     ]
    }
   ],
   "source": [
    "for name, param in ag_model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = torch.load('/home/quanguet/Downloads/attn_misc_lstm_13_July.pth')['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_model.load_my_state_dict(model_dict)\n",
    "ag_model_dict = ag_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.text_encoder.text_embeddings.tok_embedding.weight tensor(0)\n",
      "encoder.text_encoder.text_embeddings.pos_embedding.pe tensor(0)\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.weight_ih_l0 tensor(0)\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.weight_hh_l0 tensor(0)\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.bias_ih_l0 tensor(0)\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.bias_hh_l0 tensor(0)\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.weight_ih_l0_reverse tensor(0)\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.weight_hh_l0_reverse tensor(0)\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.bias_ih_l0_reverse tensor(0)\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.bias_hh_l0_reverse tensor(0)\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.weight_ih_l1 tensor(0)\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.weight_hh_l1 tensor(0)\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.bias_ih_l1 tensor(0)\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.bias_hh_l1 tensor(0)\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.weight_ih_l1_reverse tensor(0)\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.weight_hh_l1_reverse tensor(0)\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.bias_ih_l1_reverse tensor(0)\n",
      "encoder.text_encoder.hist_encoder.encoder.rnn_module.bias_hh_l1_reverse tensor(0)\n",
      "encoder.text_encoder.hist_encoder.hist_linear.weight tensor(0)\n",
      "encoder.text_encoder.hist_encoder.hist_linear.bias tensor(0)\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.weight_ih_l0 tensor(0)\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.weight_hh_l0 tensor(0)\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.bias_ih_l0 tensor(0)\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.bias_hh_l0 tensor(0)\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.weight_ih_l0_reverse tensor(0)\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.weight_hh_l0_reverse tensor(0)\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.bias_ih_l0_reverse tensor(0)\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.bias_hh_l0_reverse tensor(0)\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.weight_ih_l1 tensor(0)\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.weight_hh_l1 tensor(0)\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.bias_ih_l1 tensor(0)\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.bias_hh_l1 tensor(0)\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.weight_ih_l1_reverse tensor(0)\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.weight_hh_l1_reverse tensor(0)\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.bias_ih_l1_reverse tensor(0)\n",
      "encoder.text_encoder.ques_encoder.encoder.rnn_module.bias_hh_l1_reverse tensor(0)\n",
      "encoder.text_encoder.ques_encoder.ques_linear.weight tensor(0)\n",
      "encoder.text_encoder.ques_encoder.ques_linear.bias tensor(0)\n",
      "encoder.img_encoder.img_linear.0.weight tensor(0)\n",
      "encoder.img_encoder.img_linear.0.bias tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.0.attns.0.x_memory tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.0.attns.0.y_memory tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.0.attns.0.x_proj_linear.weight tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.0.attns.0.y_proj_linear.weight tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.0.attns.1.x_memory tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.0.attns.1.y_memory tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.0.attns.1.x_proj_linear.weight tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.0.attns.1.y_proj_linear.weight tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.0.attns.2.x_memory tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.0.attns.2.y_memory tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.0.attns.2.x_proj_linear.weight tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.0.attns.2.y_proj_linear.weight tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.0.norms.0.linear.0.weight tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.0.norms.0.linear.0.bias tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.0.norms.1.linear.0.weight tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.0.norms.1.linear.0.bias tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.0.norms.2.linear.0.weight tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.0.norms.2.linear.0.bias tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.1.attns.0.x_memory tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.1.attns.0.y_memory tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.1.attns.0.x_proj_linear.weight tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.1.attns.0.y_proj_linear.weight tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.1.attns.1.x_memory tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.1.attns.1.y_memory tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.1.attns.1.x_proj_linear.weight tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.1.attns.1.y_proj_linear.weight tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.1.attns.2.x_memory tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.1.attns.2.y_memory tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.1.attns.2.x_proj_linear.weight tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.1.attns.2.y_proj_linear.weight tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.1.norms.0.linear.0.weight tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.1.norms.0.linear.0.bias tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.1.norms.1.linear.0.weight tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.1.norms.1.linear.0.bias tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.1.norms.2.linear.0.weight tensor(0)\n",
      "encoder.attn_encoder.cross_attn_encoder.1.norms.2.linear.0.bias tensor(0)\n",
      "encoder.summaries.0.attn_linear.0.weight tensor(0)\n",
      "encoder.summaries.0.attn_linear.0.bias tensor(0)\n",
      "encoder.summaries.0.attn_linear.2.weight tensor(0)\n",
      "encoder.summaries.0.attn_linear.2.bias tensor(0)\n",
      "encoder.summaries.1.attn_linear.0.weight tensor(0)\n",
      "encoder.summaries.1.attn_linear.0.bias tensor(0)\n",
      "encoder.summaries.1.attn_linear.2.weight tensor(0)\n",
      "encoder.summaries.1.attn_linear.2.bias tensor(0)\n",
      "encoder.summaries.2.attn_linear.0.weight tensor(0)\n",
      "encoder.summaries.2.attn_linear.0.bias tensor(0)\n",
      "encoder.summaries.2.attn_linear.2.weight tensor(0)\n",
      "encoder.summaries.2.attn_linear.2.bias tensor(0)\n",
      "encoder.encoder_linear.0.weight tensor(0)\n",
      "encoder.encoder_linear.0.bias tensor(0)\n",
      "encoder.encoder_linear.2.weight tensor(0)\n",
      "encoder.encoder_linear.2.bias tensor(0)\n",
      "decoder.gen_decoder.word_embed.weight tensor(0)\n",
      "decoder.gen_decoder.answer_rnn.weight_ih_l0 tensor(0)\n",
      "decoder.gen_decoder.answer_rnn.weight_hh_l0 tensor(0)\n",
      "decoder.gen_decoder.answer_rnn.bias_ih_l0 tensor(0)\n",
      "decoder.gen_decoder.answer_rnn.bias_hh_l0 tensor(0)\n",
      "decoder.gen_decoder.answer_rnn.weight_ih_l1 tensor(0)\n",
      "decoder.gen_decoder.answer_rnn.weight_hh_l1 tensor(0)\n",
      "decoder.gen_decoder.answer_rnn.bias_ih_l1 tensor(0)\n",
      "decoder.gen_decoder.answer_rnn.bias_hh_l1 tensor(0)\n",
      "decoder.gen_decoder.lstm_to_words.weight tensor(0)\n",
      "decoder.gen_decoder.lstm_to_words.bias tensor(0)\n"
     ]
    }
   ],
   "source": [
    "for name in ag_model_dict:\n",
    "    if name in model_dict:\n",
    "        print(name, torch.sum(model_dict[name][0].cpu() != ag_model_dict[name][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
