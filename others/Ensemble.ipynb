{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader\n",
    "from visdial.data.dataset import VisDialDataset\n",
    "from visdial.metrics import SparseGTMetrics, NDCG, scores_to_ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val2018] Tokenizing questions...\n",
      "[val2018] Tokenizing answers...\n",
      "[val2018] Tokenizing captions...\n",
      "genome_path None\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "config_path = '/home/quang/checkpoints/abci/s41/config.json'\n",
    "split = 'val'\n",
    "\n",
    "with open(config_path) as file:\n",
    "    config = json.load(file)\n",
    "\n",
    "\n",
    "eval_dataset = VisDialDataset(config, split='val')\n",
    "\n",
    "eval_dataloader = DataLoader(eval_dataset,\n",
    "                            batch_size=1)\n",
    "\n",
    "sparse_metrics = SparseGTMetrics()\n",
    "ndcg = NDCG()\n",
    "\n",
    "round_ids = []\n",
    "im_ids = []\n",
    "ans_inds = []\n",
    "gt_relevances = []\n",
    "\n",
    "for batch in eval_dataloader:\n",
    "    round_ids.append(batch['round_id'])\n",
    "    im_ids.append(batch['img_ids'])\n",
    "    if split == 'val':\n",
    "        ans_inds.append(batch['ans_ind'])\n",
    "        gt_relevances.append(batch[\"gt_relevance\"])\n",
    "\n",
    "round_ids = torch.stack(round_ids, dim=0).view(-1)\n",
    "im_ids = torch.stack(im_ids, dim=0).view(-1)\n",
    "ans_inds = torch.stack(ans_inds, dim=0).view(-1, 10)\n",
    "gt_relevances = torch.stack(gt_relevances, dim=0).view(-1, 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the Ensemble for Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/quang/checkpoints/s11/finetune/lr_5e-05/CosineLR/ranks/val/ckpt_4/checkpoint_11.pth_disc.pkl\n",
      "/home/quang/checkpoints/s13/finetune/lr_5e-05/CosineLR/ranks/val/ckpt_4/checkpoint_11.pth_disc.pkl\n",
      "/home/quang/checkpoints/s19/finetune/lr_5e-05/CosineLR/ranks/val/ckpt_4/checkpoint_11.pth_disc.pkl\n",
      "/home/quang/checkpoints/s21/finetune/lr_5e-05/CosineLR/ranks/val/ckpt_4/checkpoint_11.pth_disc.pkl\n",
      "/home/quang/checkpoints/s22/finetune/lr_5e-05/CosineLR/ranks/val/ckpt_4/checkpoint_11.pth_disc.pkl\n",
      "/home/quang/checkpoints/s23/finetune/lr_5e-05/CosineLR/ranks/val/ckpt_4/checkpoint_11.pth_disc.pkl\n",
      "/home/quang/checkpoints/s24/finetune/lr_5e-05/CosineLR/ranks/val/ckpt_4/checkpoint_11.pth_disc.pkl\n",
      "/home/quang/checkpoints/s26/finetune/lr_5e-05/CosineLR/ranks/val/ckpt_4/checkpoint_11.pth_disc.pkl\n",
      "/home/quang/checkpoints/ranks/val/no_ft_ckpt_4/ensemble_11_13_19_21_22_23_24_26.json\n"
     ]
    }
   ],
   "source": [
    "split = 'test'\n",
    "model_indices = [13, 15, 19, 21, 22, 23, 24,25,26]\n",
    "model_indices = [str(idx) for idx in model_indices]\n",
    "pickle_paths = ['/home/quang/checkpoints/s{0}/ranks/test/no_ft_ckpt_4/disc.pkl'.format(idx) for idx in model_indices]\n",
    "rank_output_path = '/home/quang/checkpoints/ranks/test/no_ft_ckpt_4/ensemble_{}.json'.format(\"_\".join(model_indices))\n",
    "\n",
    "all_outputs, all_img_ids, all_round_ids, all_ans_ids, all_gt_relevance = [], [], [], [], []\n",
    "\n",
    "for pickle_path in pickle_paths:\n",
    "    with open(pickle_path, 'rb') as f:\n",
    "        x = pickle.load(f)\n",
    "        outputs, img_ids, round_ids = x\n",
    "        img_ids = torch.stack(img_ids, dim=0).view(-1)\n",
    "        outputs = torch.stack(outputs, dim=0).view(-1, 1, 100)\n",
    "        round_ids = torch.stack(round_ids, dim=0).view(-1)\n",
    "        all_outputs.append(outputs)\n",
    "        all_img_ids.append(img_ids)\n",
    "        all_round_ids.append(round_ids)\n",
    "\n",
    "avg_output = torch.zeros_like(all_outputs[0])\n",
    "# print(avg_output.shape)\n",
    "\n",
    "for out in all_outputs:\n",
    "    avg_output += out \n",
    "avg_output /= float(len(all_outputs))\n",
    "\n",
    "ranks = scores_to_ranks(avg_output)\n",
    "\n",
    "num_rounds = all_round_ids[0]\n",
    "ranks_json = []\n",
    "\n",
    "for i in range(len(img_ids)):\n",
    "    if split == 'test':\n",
    "        ranks_json.append(\n",
    "                {\n",
    "                    \"image_id\": img_ids[i].item(),\n",
    "                    \"round_id\": int(num_rounds[i].item()),\n",
    "                    \"ranks\"   : [rank.item() for rank in ranks[i][0]],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "os.makedirs(os.path.dirname(rank_output_path), exist_ok=True)\n",
    "json.dump(ranks_json, open(rank_output_path, \"w\"))\n",
    "\n",
    "print(rank_output_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/home/quang/checkpoints/s11/finetune/lr_5e-05/CosineLR/ranks/val/ft_ckpt_4/': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "ls /home/quang/checkpoints/s11/finetune/lr_5e-05/CosineLR/ranks/val/ft_ckpt_4/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the Ensemble Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/quang/checkpoints/s25/ranks/val/no_ft_ckpt_4/disc.pkl\n",
      "compute scores...\n",
      "ndcg,mrr,r@1,r@5,r@10,mean,\n",
      "0.5952447056770325,0.6482028365135193,0.5139050483703613,0.8146317601203918,0.9053294658660889,4.00227689743042,"
     ]
    }
   ],
   "source": [
    "split = 'val'\n",
    "model_indices = [11, 13, 19, 21, 22, 23, 24, 26]\n",
    "model_indices = [str(idx) for idx in model_indices]\n",
    "pickle_paths = ['/home/quang/checkpoints/s{0}/finetune/lr_5e-05/CosineLR/ranks/{1}/ckpt_3/checkpoint_11.pth_disc.pkl'.format(idx, split) for idx in model_indices]\n",
    "rank_output_path = '/home/quang/checkpoints/ranks/{}/no_ft_ckpt_4/ensemble_{}.json'.format(split, \"_\".join(model_indices))\n",
    "pickle_paths = ['/home/quang/checkpoints/s25/ranks/val/no_ft_ckpt_4/disc.pkl']\n",
    "    \n",
    "all_outputs, all_img_ids, all_round_ids, all_ans_ids, all_gt_relevance = [], [], [], [], []\n",
    "\n",
    "for pickle_path in pickle_paths:\n",
    "    print(pickle_path)\n",
    "    with open(pickle_path, 'rb') as f:\n",
    "        x = pickle.load(f)\n",
    "        outputs, img_ids, _ = x\n",
    "        img_ids = torch.stack(img_ids, dim=0).view(-1)\n",
    "        outputs = torch.stack(outputs, dim=0).view(-1, 10, 100)\n",
    "        all_outputs.append(outputs)\n",
    "        all_img_ids.append(img_ids)\n",
    "        all_round_ids.append(round_ids)\n",
    "\n",
    "\n",
    "for im_id, img_id in zip(im_ids, img_ids):\n",
    "    if im_id != img_id:\n",
    "        print(\"False\")\n",
    "\n",
    "avg_output = torch.zeros_like(all_outputs[0])\n",
    "# print(avg_output.shape)\n",
    "\n",
    "for out in all_outputs:\n",
    "    avg_output += out \n",
    "avg_output /= float(len(all_outputs))\n",
    "\n",
    "\n",
    "print(\"compute scores...\")\n",
    "sparse_metrics.observe(avg_output, ans_inds)\n",
    "\n",
    "rel_output = avg_output[torch.arange(avg_output.size(0)), round_ids - 1, :]\n",
    "ndcg.observe(rel_output, gt_relevances)\n",
    "\n",
    "all_metrics = {}\n",
    "all_metrics.update(sparse_metrics.retrieve(reset=True))\n",
    "all_metrics.update(ndcg.retrieve(reset=True))\n",
    "val_keys = ['ndcg', 'mrr', 'r@1', 'r@5', 'r@10', 'mean']\n",
    "for key in val_keys:\n",
    "    print(key, end=',')\n",
    "print()\n",
    "for key in val_keys:\n",
    "    print(all_metrics[key], end=',')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/quang/checkpoints/abci/s41/finetune/lr_1e-05/CosineLR/ranks/val/ckpt_0/checkpoint_13.pth_disc.pkl\n",
      "/home/quang/checkpoints/abci/s42/finetune/lr_1e-05/CosineLR/ranks/val/ckpt_0/checkpoint_14.pth_disc.pkl\n",
      "/home/quang/checkpoints/abci/s44/finetune/lr_1e-05/CosineLR/ranks/val/ckpt_0/checkpoint_14.pth_disc.pkl\n",
      "/home/quang/checkpoints/abci/s45/finetune/lr_1e-05/CosineLR/ranks/val/ckpt_0/checkpoint_14.pth_disc.pkl\n",
      "/home/quang/checkpoints/abci/n41/finetune/lr_1e-05/CosineLR/ranks/val/ckpt_0/checkpoint_14.pth_disc.pkl\n",
      "/home/quang/checkpoints/abci/n42/finetune/lr_1e-05/CosineLR/ranks/val/ckpt_0/checkpoint_14.pth_disc.pkl\n",
      "compute scores...\n",
      "ndcg,mrr,r@1,r@5,r@10,mean,\n",
      "0.6778573989868164,0.6218511462211609,0.4948643445968628,0.7744670510292053,0.8721414804458618,4.906104564666748,"
     ]
    }
   ],
   "source": [
    "split = 'val'\n",
    "sparse_metrics = SparseGTMetrics()\n",
    "ndcg = NDCG()\n",
    "\n",
    "\n",
    "pickle_paths = [\n",
    "    '/home/quang/checkpoints/abci/s41/finetune/lr_1e-05/CosineLR/ranks/val/ckpt_0/checkpoint_13.pth_disc.pkl',\n",
    "    '/home/quang/checkpoints/abci/s42/finetune/lr_1e-05/CosineLR/ranks/val/ckpt_0/checkpoint_14.pth_disc.pkl',\n",
    "    '/home/quang/checkpoints/abci/s44/finetune/lr_1e-05/CosineLR/ranks/val/ckpt_0/checkpoint_14.pth_disc.pkl',\n",
    "    '/home/quang/checkpoints/abci/s45/finetune/lr_1e-05/CosineLR/ranks/val/ckpt_0/checkpoint_14.pth_disc.pkl',\n",
    "    '/home/quang/checkpoints/abci/n41/finetune/lr_1e-05/CosineLR/ranks/val/ckpt_0/checkpoint_14.pth_disc.pkl',\n",
    "    '/home/quang/checkpoints/abci/n42/finetune/lr_1e-05/CosineLR/ranks/val/ckpt_0/checkpoint_14.pth_disc.pkl',\n",
    "]\n",
    "all_outputs, all_img_ids, all_round_ids, all_ans_ids, all_gt_relevance = [], [], [], [], []\n",
    "\n",
    "for pickle_path in pickle_paths:\n",
    "    print(pickle_path)\n",
    "    with open(pickle_path, 'rb') as f:\n",
    "        x = pickle.load(f)\n",
    "        outputs, img_ids, round_ids = x\n",
    "        img_ids = torch.stack(img_ids, dim=0).view(-1)\n",
    "        outputs = torch.stack(outputs, dim=0).view(-1, 10, 100)\n",
    "        round_ids = torch.stack(round_ids, dim=0).view(-1)\n",
    "        all_outputs.append(outputs)\n",
    "        all_img_ids.append(img_ids)\n",
    "        all_round_ids.append(round_ids)\n",
    "\n",
    "\n",
    "avg_output = torch.zeros_like(all_outputs[0])\n",
    "\n",
    "for out in all_outputs:\n",
    "    avg_output += out \n",
    "avg_output /= float(len(all_outputs))\n",
    "\n",
    "\n",
    "print(\"compute scores...\")\n",
    "sparse_metrics.observe(avg_output, ans_inds)\n",
    "\n",
    "rel_output = avg_output[torch.arange(avg_output.size(0)), round_ids - 1, :]\n",
    "ndcg.observe(rel_output, gt_relevances)\n",
    "\n",
    "all_metrics = {}\n",
    "all_metrics.update(sparse_metrics.retrieve(reset=True))\n",
    "all_metrics.update(ndcg.retrieve(reset=True))\n",
    "val_keys = ['ndcg', 'mrr', 'r@1', 'r@5', 'r@10', 'mean']\n",
    "for key in val_keys:\n",
    "    print(key, end=',')\n",
    "print()\n",
    "for key in val_keys:\n",
    "    print(all_metrics[key], end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'val'\n",
    "model_indices = [11, 13, 19, 21, 22, 23, 24, 26]\n",
    "model_indices = [str(idx) for idx in model_indices]\n",
    "pickle_paths = ['/home/quang/checkpoints/s{0}/finetune/lr_5e-05/CosineLR/ranks/{1}/ckpt_3/checkpoint_11.pth_disc.pkl'.format(idx, split) for idx in model_indices]\n",
    "rank_output_path = '/home/quang/checkpoints/ranks/{}/no_ft_ckpt_4/ensemble_{}.json'.format(split, \"_\".join(model_indices))\n",
    "pickle_paths = ['/home/quang/checkpoints/s25/ranks/val/no_ft_ckpt_4/disc.pkl']\n",
    "    \n",
    "all_outputs, all_img_ids, all_round_ids, all_ans_ids, all_gt_relevance = [], [], [], [], []\n",
    "\n",
    "for pickle_path in pickle_paths:\n",
    "    print(pickle_path)\n",
    "    with open(pickle_path, 'rb') as f:\n",
    "        x = pickle.load(f)\n",
    "        outputs, img_ids, _ = x\n",
    "        img_ids = torch.stack(img_ids, dim=0).view(-1)\n",
    "        outputs = torch.stack(outputs, dim=0).view(-1, 10, 100)\n",
    "        all_outputs.append(outputs)\n",
    "        all_img_ids.append(img_ids)\n",
    "        all_round_ids.append(round_ids)\n",
    "\n",
    "\n",
    "for im_id, img_id in zip(im_ids, img_ids):\n",
    "    if im_id != img_id:\n",
    "        print(\"False\")\n",
    "\n",
    "avg_output = torch.zeros_like(all_outputs[0])\n",
    "# print(avg_output.shape)\n",
    "\n",
    "for out in all_outputs:\n",
    "    avg_output += out \n",
    "avg_output /= float(len(all_outputs))\n",
    "\n",
    "\n",
    "print(\"compute scores...\")\n",
    "sparse_metrics.observe(avg_output, ans_inds)\n",
    "\n",
    "rel_output = avg_output[torch.arange(avg_output.size(0)), round_ids - 1, :]\n",
    "ndcg.observe(rel_output, gt_relevances)\n",
    "\n",
    "all_metrics = {}\n",
    "all_metrics.update(sparse_metrics.retrieve(reset=True))\n",
    "all_metrics.update(ndcg.retrieve(reset=True))\n",
    "val_keys = ['ndcg', 'mrr', 'r@1', 'r@5', 'r@10', 'mean']\n",
    "for key in val_keys:\n",
    "    print(key, end=',')\n",
    "print()\n",
    "for key in val_keys:\n",
    "    print(all_metrics[key], end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/quang/checkpoints/ranks/val/no_ft_ckpt_4/ensemble_19_22_23_24_25_26.json\n"
     ]
    }
   ],
   "source": [
    "print(rank_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6,0.8491790890693665,0.5173311233520508,0.3804748058319092,0.6699128150939941,0.7983042597770691,6.766472816467285,\n",
      "7,0.8558176159858704,0.5051973462104797,0.36419573426246643,0.6630814075469971,0.7957364320755005,6.8550872802734375,\n",
      "8,0.8621454834938049,0.5007437467575073,0.35857558250427246,0.6618701815605164,0.7950581312179565,6.876114368438721,\n",
      "9,0.8676555156707764,0.4963180124759674,0.3525193929672241,0.6590600609779358,0.7939438223838806,6.899176120758057,\n",
      "10,0.8723283410072327,0.49351394176483154,0.348982572555542,0.6577519178390503,0.7942345142364502,6.914486408233643,\n"
     ]
    }
   ],
   "source": [
    "for ckpt in range(5, 10):\n",
    "    pickle_paths =['/media/local_workspace/quang/checkpoints/visdial/CVPR/train_simple/lr001/12_epochs/s06_simple_branch/finetune/lr_{}e-05/CosineLR/ranks/val/ckpt_{}/checkpoint_11.pth_{}.pkl', \n",
    "               '/media/local_workspace/quang/checkpoints/visdial/CVPR/train_simple/lr001/12_epochs/s07_simple_branch/finetune/lr_{}e-05/CosineLR/ranks/val/ckpt_{}/checkpoint_11.pth_{}.pkl', \n",
    "               '/media/local_workspace/quang/checkpoints/visdial/CVPR/train_simple/lr001/12_epochs/s08_simple_branch/finetune/lr_{}e-05/CosineLR/ranks/val/ckpt_{}/checkpoint_11.pth_{}.pkl', \n",
    "               '/media/local_workspace/quang/checkpoints/visdial/CVPR/train_simple/lr001/12_epochs/s09_simple_branch/finetune/lr_{}e-05/CosineLR/ranks/val/ckpt_{}/checkpoint_last.pth_{}.pkl', \n",
    "               '/media/local_workspace/quang/checkpoints/visdial/CVPR/train_simple/lr001/12_epochs/s10_simple_branch/finetune/lr_{}e-05/CosineLR/ranks/val/ckpt_{}/checkpoint_11.pth_{}.pkl', \n",
    "               '/media/local_workspace/quang/checkpoints/visdial/CVPR/train_simple/lr001/12_epochs/s11_simple_branch/finetune/lr_{}e-05/CosineLR/ranks/val/ckpt_{}/checkpoint_11.pth_{}.pkl', \n",
    "                 ]\n",
    "\n",
    "    pickle_paths = [p.format(lr, str(ckpt), decoder) for p in pickle_paths]\n",
    "    rank_output_path = '/media/local_workspace/quang/checkpoints/visdial/CVPR/train_simple/lr001/12_epochs/ranks/val/ensemble_s67891011_ckpt_2_ft.json'\n",
    "    \n",
    "    \n",
    "    all_outputs, all_img_ids, all_round_ids, all_ans_ids   , all_gt_relevance = [], [], [], [], []\n",
    "\n",
    "    for pickle_path in pickle_paths:\n",
    "        with open(pickle_path, 'rb') as f:\n",
    "            x = pickle.load(f)\n",
    "            outputs, img_ids, _ = x\n",
    "            img_ids = torch.stack(img_ids, dim=0).view(-1)\n",
    "            outputs = torch.stack(outputs, dim=0).view(-1, 10, 100)\n",
    "            all_outputs.append(outputs)\n",
    "            all_img_ids.append(img_ids)\n",
    "            all_round_ids.append(round_ids)\n",
    "\n",
    "\n",
    "    for im_id, img_id in zip(im_ids, img_ids):\n",
    "        if im_id != img_id:\n",
    "            print(\"False\")\n",
    "\n",
    "    avg_output = torch.zeros_like(all_outputs[0])\n",
    "    # print(avg_output.shape)\n",
    "\n",
    "    for out in all_outputs:\n",
    "        avg_output += out \n",
    "    avg_output /= float(len(all_outputs))\n",
    "\n",
    "\n",
    "\n",
    "    sparse_metrics.observe(avg_output, ans_inds)\n",
    "\n",
    "    rel_output = avg_output[torch.arange(avg_output.size(0)), round_ids - 1, :]\n",
    "    ndcg.observe(rel_output, gt_relevances)\n",
    "\n",
    "    all_metrics = {}\n",
    "    all_metrics.update(sparse_metrics.retrieve(reset=True))\n",
    "    all_metrics.update(ndcg.retrieve(reset=True))\n",
    "    val_keys = ['ndcg', 'mrr', 'r@1', 'r@5', 'r@10', 'mean']\n",
    "    print(f\"{ckpt + 1}\", end=',')\n",
    "    \n",
    "    for key in val_keys:\n",
    "        print(all_metrics[key], end=',')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = scores_to_ranks(avg_output)\n",
    "\n",
    "ranks_json = []\n",
    "\n",
    "for i in range(len(img_ids)):\n",
    "    if split == 'val':\n",
    "        for j in range(10):\n",
    "            ranks_json.append(\n",
    "                    {\n",
    "                        \"image_id\": img_ids[i].item(),\n",
    "                        \"round_id\": int(j + 1),\n",
    "                        \"ranks\"   : [rank.item() for rank in ranks[i][j]],\n",
    "                        }\n",
    "                    )\n",
    "            \n",
    "import os\n",
    "import json\n",
    "\n",
    "os.makedirs(os.path.dirname(rank_output_path), exist_ok=True)\n",
    "json.dump(ranks_json, open(rank_output_path, \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt 0\n",
      "/media/local_workspace/quang/checkpoints/visdial/CVPR/train_simple/lr001/12_epochs/ranks/test/ensemble_s67891011_ckpt_3_4_ft.json\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "\n",
    "lr = '5'\n",
    "split = 'test'\n",
    "\n",
    "# for ckpt in [3, 2, 0]:\n",
    "print(\"ckpt\", ckpt)\n",
    "\n",
    "# pickle_paths =[\n",
    "#            '/media/local_workspace/quang/checkpoints/visdial/CVPR/train_simple/lr001/12_epochs/s06_simple_branch/finetune/lr_{}e-05/CosineLR/ranks/test/ckpt_{}/disc.pkl', \n",
    "#            '/media/local_workspace/quang/checkpoints/visdial/CVPR/train_simple/lr001/12_epochs/s07_simple_branch/finetune/lr_{}e-05/CosineLR/ranks/test/ckpt_{}/disc.pkl', \n",
    "#            '/media/local_workspace/quang/checkpoints/visdial/CVPR/train_simple/lr001/12_epochs/s08_simple_branch/finetune/lr_{}e-05/CosineLR/ranks/test/ckpt_{}/disc.pkl', \n",
    "#            '/media/local_workspace/quang/checkpoints/visdial/CVPR/train_simple/lr001/12_epochs/s09_simple_branch/finetune/lr_{}e-05/CosineLR/ranks/test/ckpt_{}/disc.pkl', \n",
    "#            '/media/local_workspace/quang/checkpoints/visdial/CVPR/train_simple/lr001/12_epochs/s10_simple_branch/finetune/lr_{}e-05/CosineLR/ranks/test/ckpt_{}/disc.pkl', \n",
    "#            '/media/local_workspace/quang/checkpoints/visdial/CVPR/train_simple/lr001/12_epochs/s11_simple_branch/finetune/lr_{}e-05/CosineLR/ranks/test/ckpt_{}/disc.pkl', \n",
    "#              ]\n",
    "\n",
    "# pickle_paths = [p.format(lr, str(ckpt)) for p in pickle_paths]\n",
    "# rank_output_path = '/media/local_workspace/quang/checkpoints/visdial/CVPR/train_simple/lr001/12_epochs/ranks/test/ensemble_s67891011_ckpt_{}_ft.json'.format(ckpt)\n",
    "\n",
    "pickle_paths =[\n",
    "           '/media/local_workspace/quang/checkpoints/visdial/CVPR/train_simple/lr001/12_epochs/s06_simple_branch/finetune/lr_{}e-05/CosineLR/ranks/test/ckpt_3/disc.pkl', \n",
    "           '/media/local_workspace/quang/checkpoints/visdial/CVPR/train_simple/lr001/12_epochs/s07_simple_branch/finetune/lr_{}e-05/CosineLR/ranks/test/ckpt_3/disc.pkl', \n",
    "           '/media/local_workspace/quang/checkpoints/visdial/CVPR/train_simple/lr001/12_epochs/s08_simple_branch/finetune/lr_{}e-05/CosineLR/ranks/test/ckpt_3/disc.pkl', \n",
    "           '/media/local_workspace/quang/checkpoints/visdial/CVPR/train_simple/lr001/12_epochs/s09_simple_branch/finetune/lr_{}e-05/CosineLR/ranks/test/ckpt_3/disc.pkl', \n",
    "           '/media/local_workspace/quang/checkpoints/visdial/CVPR/train_simple/lr001/12_epochs/s10_simple_branch/finetune/lr_{}e-05/CosineLR/ranks/test/ckpt_3/disc.pkl', \n",
    "           '/media/local_workspace/quang/checkpoints/visdial/CVPR/train_simple/lr001/12_epochs/s11_simple_branch/finetune/lr_{}e-05/CosineLR/ranks/test/ckpt_3/disc.pkl',\n",
    "           '/media/local_workspace/quang/checkpoints/visdial/CVPR/train_simple/lr001/12_epochs/s06_simple_branch/finetune/lr_{}e-05/CosineLR/ranks/test/ckpt_4/disc.pkl', \n",
    "           '/media/local_workspace/quang/checkpoints/visdial/CVPR/train_simple/lr001/12_epochs/s07_simple_branch/finetune/lr_{}e-05/CosineLR/ranks/test/ckpt_4/disc.pkl', \n",
    "           '/media/local_workspace/quang/checkpoints/visdial/CVPR/train_simple/lr001/12_epochs/s08_simple_branch/finetune/lr_{}e-05/CosineLR/ranks/test/ckpt_4/disc.pkl', \n",
    "           '/media/local_workspace/quang/checkpoints/visdial/CVPR/train_simple/lr001/12_epochs/s09_simple_branch/finetune/lr_{}e-05/CosineLR/ranks/test/ckpt_4/disc.pkl', \n",
    "           '/media/local_workspace/quang/checkpoints/visdial/CVPR/train_simple/lr001/12_epochs/s10_simple_branch/finetune/lr_{}e-05/CosineLR/ranks/test/ckpt_4/disc.pkl', \n",
    "           '/media/local_workspace/quang/checkpoints/visdial/CVPR/train_simple/lr001/12_epochs/s11_simple_branch/finetune/lr_{}e-05/CosineLR/ranks/test/ckpt_4/disc.pkl'   \n",
    "]   \n",
    "    \n",
    "pickle_paths = [p.format(lr) for p in pickle_paths]\n",
    "rank_output_path = '/media/local_workspace/quang/checkpoints/visdial/CVPR/train_simple/lr001/12_epochs/ranks/test/ensemble_s67891011_ckpt_3_4_ft.json'\n",
    "\n",
    "\n",
    "all_outputs, all_img_ids, all_round_ids, all_ans_ids, all_gt_relevance = [], [], [], [], []\n",
    "\n",
    "for pickle_path in pickle_paths:\n",
    "    with open(pickle_path, 'rb') as f:\n",
    "        x = pickle.load(f)\n",
    "        outputs, img_ids, round_ids = x\n",
    "        img_ids = torch.stack(img_ids, dim=0).view(-1)\n",
    "        outputs = torch.stack(outputs, dim=0).view(-1, 1, 100)\n",
    "        round_ids = torch.stack(round_ids, dim=0).view(-1)\n",
    "        all_outputs.append(outputs)\n",
    "        all_img_ids.append(img_ids)\n",
    "        all_round_ids.append(round_ids)\n",
    "\n",
    "avg_output = torch.zeros_like(all_outputs[0])\n",
    "# print(avg_output.shape)\n",
    "\n",
    "for out in all_outputs:\n",
    "    avg_output += out \n",
    "avg_output /= float(len(all_outputs))\n",
    "\n",
    "ranks = scores_to_ranks(avg_output)\n",
    "\n",
    "num_rounds = all_round_ids[0]\n",
    "ranks_json = []\n",
    "\n",
    "for i in range(len(img_ids)):\n",
    "    if split == 'test':\n",
    "        ranks_json.append(\n",
    "                {\n",
    "                    \"image_id\": img_ids[i].item(),\n",
    "                    \"round_id\": int(num_rounds[i].item()),\n",
    "                    \"ranks\"   : [rank.item() for rank in ranks[i][0]],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "os.makedirs(os.path.dirname(rank_output_path), exist_ok=True)\n",
    "json.dump(ranks_json, open(rank_output_path, \"w\"))\n",
    "\n",
    "print(rank_output_path)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old scripts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outputs, all_img_ids, all_round_ids, all_ans_ids, all_gt_relevance = [], [], [], [], []\n",
    "\n",
    "for pickle_path in pickle_paths:\n",
    "    with open(pickle_path, 'rb') as f:\n",
    "        x = pickle.load(f)\n",
    "        outputs, img_ids, round_ids = x\n",
    "        img_ids = torch.stack(img_ids, dim=0).view(-1)\n",
    "        round_ids = torch.stack(round_ids, dim=0).view(-1)\n",
    "        outputs = torch.stack(outputs, dim=0).view(-1, 10, 100)\n",
    "        all_outputs.append(outputs)\n",
    "        all_img_ids.append(img_ids)\n",
    "        all_round_ids.append(round_ids)\n",
    "\n",
    "\n",
    "ranks_json = []\n",
    "\n",
    "for k in range(len(all_outputs[0])):\n",
    "    \n",
    "    img_ids = all_img_ids[0][k]\n",
    "    num_rounds = all_round_ids[0][k]\n",
    "    \n",
    "    output = torch.zeros_like(all_outputs[0][k])\n",
    "    \n",
    "    for kind in range(len(all_outputs)):\n",
    "        output_kind = all_outputs[kind][k]\n",
    "        output += output_kind\n",
    "    output = output / float(len(all_outputs))\n",
    "    \n",
    "    ranks = scores_to_ranks(output)\n",
    "    for i in range(len(img_ids)):\n",
    "        \n",
    "        if split == 'test':\n",
    "            ranks_json.append(\n",
    "            {\n",
    "                \"image_id\": img_ids[i].item(),\n",
    "                \"round_id\": int(num_rounds[i].item()),\n",
    "                \"ranks\": [rank.item() for rank in ranks[i][0]  # [batch[\"num_rounds\"][i] - 1]\n",
    "                ],\n",
    "            })\n",
    "        elif split == 'val':\n",
    "            for j in range(num_rounds[i]):\n",
    "\n",
    "                ranks_json.append(\n",
    "                        {\n",
    "                            \"image_id\": img_ids[i].item(),\n",
    "                            \"round_id\": int(j + 1),\n",
    "                            \"ranks\"   : [rank.item() for rank in ranks[i][j]],\n",
    "                            }\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.dump(ranks_json, open(rank_output_path, \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/quang/ranks/train_simple/test/ensemble_s6_7_7cosine_disc_ckpt_3_ft.json\n"
     ]
    }
   ],
   "source": [
    "print(rank_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ensemble_s6_7_7cosine_misc.json'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.basename(rank_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"NDCG (x 100)\", \"MRR (x 100)\", \"R@1\", \"R@5\", \"R@10\", \"Mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {\"test-std\": {\"MRR (x 100)\": 64.0807984826235, \"R@1\": 50.2, \"R@5\": 80.675, \"R@10\": 90.35, \"Mean\": 4.052, \"NDCG (x 100)\": 59.032664470283706}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "if out.get('test-std') is not None:\n",
    "    res = out['test-std']\n",
    "else:\n",
    "    res = out['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG (x 100),MRR (x 100),R@1,R@5,R@10,Mean,\n",
      "0.590326644702837,0.640807984826235,0.502,0.80675,0.9035,0.040519999999999994,"
     ]
    }
   ],
   "source": [
    "for key in keys:\n",
    "    print(key, end=',')\n",
    "print()\n",
    "for key in keys:\n",
    "    print(res[key]/100, end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.480000000000004"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "71.95 - 64.47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
